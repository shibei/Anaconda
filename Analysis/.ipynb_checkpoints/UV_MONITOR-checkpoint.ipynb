{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymysql as psql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pymysql.cursors\n",
    "from contextlib import contextmanager\n",
    "import smtplib\n",
    "import os\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email import encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用上下文管理器来连接数据库的函数\n",
    "@contextmanager\n",
    "def connect(server):\n",
    "    database = pymysql.connect(**server)\n",
    "    yield database \n",
    "    database.close()\n",
    "\n",
    "#在数据库中执行命令函数\n",
    "def sqlAction(database,action):\n",
    "    with database.cursor() as cursor:\n",
    "        # 执行sql语句，进行查询\n",
    "        cursor.execute(action)\n",
    "        # 获取查询结果\n",
    "        result = cursor.fetchall()\n",
    "    # 没有设置默认自动提交，需要主动提交，以保存所执行的语句\n",
    "    database.commit()\n",
    "    return result\n",
    "\n",
    "class SqlServer(object):  # 定义sqlServer类，用来连接到mysql获取数据\n",
    "    \"\"\"docstring for sqlServer\"\"\"\n",
    "    #   server的数据结构示例\n",
    "    # {\"server\": { #数据库信息\n",
    "    #     'host': '121.40.211.161',#ip地址\n",
    "    #     'port': 58799,端口号\n",
    "    #     'user': 'hhh',用户名\n",
    "    #     'password': '123456'密码,\n",
    "    #     'db': 'hive_statistical_results',数据库名称\n",
    "    #     'charset': 'utf8mb4',编码方式\n",
    "    #     'cursorclass': pymysql.cursors.DictCursor\n",
    "    # },\n",
    "    #     \"comm\": {命令描述和要执行的命令\n",
    "    #     'apData': \"SELECT * FROM `ap_count`\",\n",
    "    #     'uvData': \"SELECT * FROM `funnel_model2`\"\n",
    "    # }}\n",
    "\n",
    "    def __init__(self,server):\n",
    "        self.server = server[\"server\"]\n",
    "        self.sqlComm = server[\"comm\"]\n",
    "    \n",
    "#     只执行一条命令\n",
    "    def getOneData(self,key):\n",
    "        server = self.server\n",
    "        with connect(server) as database:\n",
    "            result = sqlAction(database,self.sqlComm[key])\n",
    "        df = pd.DataFrame(result)\n",
    "        return df\n",
    "    \n",
    "#     执行所有命令\n",
    "    def getAllData(self):\n",
    "        server = self.server\n",
    "        sqlDatas ={}\n",
    "        with connect(server) as database:\n",
    "            for key in self.sqlComm:\n",
    "                result = pd.DataFrame(sqlAction(database,self.sqlComm[key]))\n",
    "                sqlDatas[key] = result\n",
    "        return sqlDatas\n",
    "\n",
    "# 获取x天之前的日期\n",
    "def getDate(x):\n",
    "    today = datetime.date.today()\n",
    "    oneday = datetime.timedelta(days=x)\n",
    "    day = today-oneday\n",
    "    return day\n",
    "\n",
    "#重新排序列\n",
    "def reColumns(df, columns=['hos_id','dhcp', 'portal', \n",
    "                           'prelogin', 'login', 'webforward', \n",
    "                           'hardforward', 'log_date']):\n",
    "    for x in range(len(columns)):\n",
    "        p = df.pop(columns[x])\n",
    "        df.insert(x, columns[x], p)\n",
    "    return df\n",
    "\n",
    "def get400Data(day,cycle,path = r'/root/ipython/400与回访医院报修记录单统计表 (更改版).xlsx'):\n",
    "    day1 = getDate(day)\n",
    "    day2 = getDate(day+cycle)\n",
    "    data400 = pd.read_excel(path)\n",
    "    data400.columns = data400.loc[0].values.tolist()\n",
    "    data400 = data400.drop(0)\n",
    "    data4001 = pd.DataFrame([])\n",
    "    data4001[[r'报修日期', r'解决问题日期']] = data400[\n",
    "        [r'报修日期', r'解决问题日期']].dropna().astype('datetime64[ns]')\n",
    "    data4001[[r'医院名称', r'报修问题', r'解决方式', r'解决人']] = data400[\n",
    "        [r'医院名称', r'报修问题', r'解决方式', r'解决人']]\n",
    "    return data4001[(data4001[r'报修日期'] >= day2) & (data4001[r'报修日期'] <= day1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRawData(day, cycle):\n",
    "\n",
    "    day0 = str(getDate(0))\n",
    "    day1 = str(getDate(day))\n",
    "    day2 = str(getDate(day+cycle))\n",
    "\n",
    "    uvBase = {\"server\": {\n",
    "        'host': '121.40.211.161',\n",
    "        'port': 58799,\n",
    "        'user': 'hhh',\n",
    "        'password': '123456',\n",
    "        'db': 'hive_statistical_results',\n",
    "        'charset': 'utf8mb4',\n",
    "        'cursorclass': pymysql.cursors.DictCursor\n",
    "    },\n",
    "        \"comm\": {\n",
    "    }}\n",
    "\n",
    "    hosBase = {\"server\": {\n",
    "        'host': '121.40.211.161',\n",
    "        'port': 58799,\n",
    "        'user': 'hhh',\n",
    "        'password': '123456',\n",
    "        'db': 'UV',\n",
    "        'charset': 'utf8mb4',\n",
    "        'cursorclass': pymysql.cursors.DictCursor\n",
    "    },\n",
    "        \"comm\": {\n",
    "    }}\n",
    "\n",
    "    devBase = {\"server\": {\n",
    "        'host': 'localhost',\n",
    "        'port': 3306,\n",
    "        'user': 'root',\n",
    "        'password': 'admin123',\n",
    "        'db': 'device',\n",
    "        'charset': 'utf8mb4',\n",
    "        'cursorclass': pymysql.cursors.DictCursor\n",
    "    },\n",
    "        \"comm\": {\n",
    "    }}\n",
    "\n",
    "    totalInfoFields = json.dumps(['HosID', 'Hospital', 'Value',\n",
    "                                  'CurrentBroadbandBandwidth', 'GatewayVendor',\n",
    "                                  'ApVendor', 'ApType', 'GWID']).strip('[').strip(']').replace('\"', '')\n",
    "\n",
    "    devInfoFields = json.dumps(['clock', 'cpuUsed', 'downSpeed',\n",
    "                                'gwid', 'starttimeLong',\n",
    "                                'status', 'wanIp']).strip('[').strip(']').replace('\"', '')\n",
    "\n",
    "    uvBase['comm']['apData'] = \"SELECT * FROM `ap_count` WHERE \\\n",
    "    `log_date` = '%s' OR `log_date` = '%s' ORDER BY \\\n",
    "    `log_date` DESC\" % (day2, day1)\n",
    "\n",
    "    uvBase['comm']['uvData'] = \"SELECT * FROM `funnel_model2` WHERE \\\n",
    "    `log_date` = '%s' OR `log_date` = '%s' ORDER BY \\\n",
    "    `log_date` DESC\" % (day2, day1)\n",
    "\n",
    "    devBase['comm']['devInfo'] = \"SELECT %s FROM `dev_info` \\\n",
    "    WHERE `date` = '%s' ORDER BY `clock` DESC LIMIT 0, 1000\" % (devInfoFields, day0)\n",
    "\n",
    "    hosBase['comm']['totalInfo'] = \"SELECT %s FROM `TOTAL_INFO_T_%s`\" % (\n",
    "        totalInfoFields, day1.replace('-', ''))\n",
    "\n",
    "    uvDatabase, hosDatabase, devDatabase = SqlServer(\n",
    "        uvBase), SqlServer(hosBase), SqlServer(devBase)\n",
    "\n",
    "    uvDataRaw, apDataRaw, hosInfoRaw, devInfoRaw = uvDatabase.getOneData('uvData'), uvDatabase.getOneData(\n",
    "        'apData'), hosDatabase.getOneData('totalInfo'), devDatabase.getOneData('devInfo')\n",
    "\n",
    "    data400Raw = get400Data(day, cycle)\n",
    "    return uvDataRaw, apDataRaw,hosInfoRaw, devInfoRaw, data400Raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 清洗数据\n",
    "def dataClean(uvData,apData):\n",
    "    reColumns(uvData)\n",
    "    uvData = uvData.replace('\\\\N', 0).fillna(0).sort_values(\n",
    "        by='log_date', ascending=False).reset_index(drop=True)\n",
    "    uvDataGood = uvData[['hos_id','dhcp', 'portal', 'prelogin',\n",
    "                         'login', 'webforward', 'hardforward']].astype('int32')\n",
    "    uvDataGood['log_date'] = uvData['log_date'].astype('datetime64[ns]')\n",
    "    uvDataGood['forward_rate'] = uvDataGood['hardforward']/uvDataGood['dhcp']\n",
    "    uvDataLite = uvDataGood.drop(\n",
    "        ['portal', 'prelogin', 'login', 'webforward'], axis=1)\n",
    "    apData = apData.replace(['福建','安徽','福建省','安徽省',''],np.nan).dropna()\n",
    "    apDataGood = apData[['hos_id','ap_count']].astype('int64')\n",
    "    apDataGood['log_date'] = apData['log_date'].astype('datetime64[ns]')\n",
    "    return uvDataGood,apDataGood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 提取n天和n+r天前的数据\n",
    "def getDateData(uvData, apData, day=1, cycle=7):\n",
    "    d1 = day\n",
    "    d2 = d1+cycle\n",
    "    day1 = getDate(d1)\n",
    "    day2 = getDate(d2)\n",
    "    uvDay1 = uvData[uvData['log_date'] == day1].reset_index(\n",
    "        drop=True).set_index('hos_id').drop('log_date', axis=1)\n",
    "    uvDay2 = uvData[uvData['log_date'] == day2].reset_index(\n",
    "        drop=True).set_index('hos_id').drop('log_date', axis=1)\n",
    "    apDay1 = apData[apData['log_date'] == day1].set_index(\n",
    "        'hos_id').drop('log_date', axis=1)\n",
    "    apDay2 = apData[apData['log_date'] == day2].set_index(\n",
    "        'hos_id').drop('log_date', axis=1)\n",
    "    uvDay1 = pd.merge(uvDay1, apDay1, left_index=True,\n",
    "                      right_index=True, how='left')\n",
    "    uvDay2 = pd.merge(uvDay2, apDay2, left_index=True,\n",
    "                      right_index=True, how='left')\n",
    "    \n",
    "    allHosid = np.union1d(uvDay1.index, uvDay2.index)\n",
    "    uvDay1 = uvDay1.reindex(allHosid, fill_value=0)\n",
    "    uvDay2 = uvDay2.reindex(allHosid, fill_value=0)\n",
    "    \n",
    "    uvDay1.insert(0, 'ap_count', uvDay1.pop('ap_count'))\n",
    "    uvDay2.insert(0, 'ap_count', uvDay2.pop('ap_count'))\n",
    "    uvDay2Lite = uvDay2[uvDay2['dhcp'] > 200]\n",
    "    uvDay1Lite = uvDay1.reindex(uvDay2Lite.index)\n",
    "    return uvDay1, uvDay2, uvDay1Lite, uvDay2Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#依靠经验值来构建的决策树\n",
    "\n",
    "def decisionTree(data,rawData,apLimit = -0.1,forwardLimit = -0.4 ,globalLimit = -0.4):\n",
    "    index = data.index #获得目录\n",
    "    splitTerm0 = data[index[0]] <= globalLimit #分裂条件0\n",
    "    if len(index) > 1:\n",
    "        splitTerm1 = data[index[1]] <= 0.5*globalLimit #分裂条件1\n",
    "    \n",
    "    #\"\"\"决策树第一层\"\"\"\n",
    "    #如果data的第一行索引名为'ap_count',并且第一行值等于-1，那么返回‘网关离线’。（AP全掉了）\n",
    "    if index[0] == 'ap_count' and data[index[0]] == -1:\n",
    "        return '网关离线' \n",
    "    \n",
    "    #如果data的第一行索引名为'ap_count',并且第一行值小于apLimi同时不等于-1，那么返回‘AP离线’。（AP掉了一部分）\n",
    "    elif index[0] == 'ap_count' and data[index[0]] <= apLimit and data[index[0]] != -1:\n",
    "        return 'AP离线'\n",
    "    \n",
    "    #如果data的第一行索引名为'ap_count',并且第一行值大于apLimit，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果AP数量没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'ap_count' and data[index[0]] > apLimit:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "    \n",
    "    \n",
    "    #\"\"\"决策树第二层\"\"\"\n",
    "    #如果data的第一行索引名为'dhcp',并且同时满足分裂条件0和1，那么返回'未知'。（莫名其妙的DHCP数就下降了）\n",
    "    elif index[0] == 'dhcp' and splitTerm0 and splitTerm1:\n",
    "        return '未知  '+index[0]+'<'+str(globalLimit)\n",
    "    \n",
    "    #如果data的第一行索引名为'dhcp',并且满足分裂条件0,不满足分裂条件1，那么返回'DHCP统计错误'。（只有DHCP数下降了）\n",
    "    elif index[0] == 'dhcp' and splitTerm0 and not splitTerm1:\n",
    "        return 'DHCP统计错误'\n",
    "    \n",
    "    #如果data的第一行索引名为'dhcp',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果DHCP数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'dhcp' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "    \n",
    "    \n",
    "    #\"\"\"决策树第三层\"\"\"\n",
    "    #如果data的第一行索引名为'portal',并且同时满足分裂条件0和1，那么返回'重定向故障'。（莫名其妙的portal数就下降了）\n",
    "    elif index[0] == 'portal' and splitTerm0 and splitTerm1:\n",
    "        return '重定向故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'portal',并且满足分裂条件0不满足分裂条件1，那么返回'portal打点故障'。（只有portal数下降了）\n",
    "    elif index[0] == 'portal' and splitTerm0 and not splitTerm1:\n",
    "        return 'portal打点故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'portal',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果portal数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'portal' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "    \n",
    "    \n",
    "    #\"\"\"决策树第四层\"\"\"\n",
    "    #如果data的第一行索引名为'prelogin',并且同时满足分裂条件0和1，那么返回'带宽负载较高（疑似）'。（预登陆人数变少了，可能是带宽造成的）\n",
    "    elif index[0] == 'prelogin' and splitTerm0 and splitTerm1:\n",
    "        return '带宽负载较高（疑似）'\n",
    "    \n",
    "    #如果data的第一行索引名为'prelogin',并且满足分裂条件0不满足分裂条件1，那么返回'prelogin打点故障'。（只有prelogin数下降了）\n",
    "    elif index[0] == 'prelogin' and splitTerm0 and not splitTerm1:\n",
    "        return 'prelogin打点故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'prelogin',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果prelogin数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'prelogin' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "    \n",
    "\n",
    "    #\"\"\"决策树第五层\"\"\"\n",
    "    #如果data的第一行索引名为'login',并且同时满足分裂条件0和1，那么返回'未知'。（莫名其妙的login数就变少了）\n",
    "    elif index[0] == 'login' and splitTerm0 and splitTerm1:\n",
    "        return '未知'+index[0]+'<'+str(globalLimit)\n",
    "    \n",
    "    #如果data的第一行索引名为'login',并且满足分裂条件0不满足分裂条件1，那么返回'login打点故障'。（只有login数下降了）\n",
    "    elif index[0] == 'login' and splitTerm0 and not splitTerm1:\n",
    "        return 'login打点故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'login',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果login数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'login' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "\n",
    "\n",
    "    #\"\"\"决策树第六层\"\"\"\n",
    "    #如果data的第一行索引名为'webforward',并且同时满足分裂条件0和1，那么返回'web放行故障'。（莫名其妙的webforward数就变少了）\n",
    "    elif index[0] == 'webforward' and splitTerm0 and splitTerm1:\n",
    "        return 'web放行故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'webforward',并且满足分裂条件0不满足分裂条件1，那么返回'webforward打点故障'。（只有webforward数下降了）\n",
    "    elif index[0] == 'webforward' and splitTerm0 and not splitTerm1:\n",
    "        return 'webforward打点故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'webforward',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果webforward数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'webforward' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "\n",
    "\n",
    "    #\"\"\"决策树第七层\"\"\"\n",
    "    #如果data的第一行索引名为'hardforward',并且满足分裂条件0，那么返回'硬件放行故障'。（莫名其妙的hardforward数就变少了）\n",
    "    elif index[0] == 'hardforward' and splitTerm0:\n",
    "        return '硬件放行故障'\n",
    "    \n",
    "    #如果data的第一行索引名为'hardforward',并且不满足分裂条件0，那么data去除第一行，其他参数保持不变，进行递归\n",
    "    #（如果hardforward数没有下降，那么进行下一步判断）\n",
    "    elif index[0] == 'hardforward' and not splitTerm0:\n",
    "        return decisionTree(data[1:],rawData,apLimit,forwardLimit,globalLimit)\n",
    "\n",
    "\n",
    "    #\"\"\"决策树第八层\"\"\"\n",
    "    #如果data的第一行索引名为'forward_rate',并且不满足分裂条件0，那么返回'正常'。（正常情况）\n",
    "    elif index[0] == 'forward_rate' and not splitTerm0:\n",
    "        return '正常'\n",
    "    \n",
    "    #如果data的第一行索引名为'forward_rate',并且满足分裂条件0，那么赋值rawData到data，globalLimit - 0.05,其他参数保持不变，进行递归\n",
    "    #（如果其他参数正常，只有forward_rate变少了，那么减小分裂系数，重新进行分析，）\n",
    "    elif index[0] == 'forward_rate' and not splitTerm0:\n",
    "        return decisionTree(rawData,rawData,apLimit,forwardLimit,globalLimit-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis(day,cycle,apLimit = -0.1,forwardLimit = -0.4 ,globalLimit = -0.4):\n",
    "    uvDataRaw, apDataRaw,hosInfoRaw, devInfoRaw, data400Raw = getRawData(day, cycle)\n",
    "    uvDataGood,apDataGood = dataClean(uvDataRaw,apDataRaw)\n",
    "    uvDay1, uvDay2, uvDay1Lite,uvDay2Lite = getDateData(uvDataGood,apDataGood,day,cycle)\n",
    "    rate =((uvDay1Lite.reindex(uvDay2Lite.index).fillna(0)-uvDay2Lite)/uvDay2Lite)\n",
    "    troubleList = {}\n",
    "    for hos in rate.index:\n",
    "        trouble = decisionTree(rate.loc[hos],rate.loc[hos],-0.1,-0.4,-0.4)\n",
    "        troubleList[hos] = trouble\n",
    "    statusSeries = pd.Series(troubleList)\n",
    "    troubleHos = statusSeries[statusSeries !='正常']\n",
    "    troubleDf = pd.DataFrame(troubleHos,columns=['故障类型'])\n",
    "    troubleDf.insert(0,'hos_id',troubleDf.index)\n",
    "    troubleRate =pd.merge(troubleDf,rate,left_on='hos_id',right_index=True)\n",
    "    troubleUV =pd.merge(troubleDf,uvDay1,left_on='hos_id',right_index=True)\n",
    "    troubleTotal = mergeDf(troubleDf,hosInfoRaw, devInfoRaw, data400Raw)\n",
    "    troubleInfo = {\n",
    "        'troubleTotal':troubleTotal,\n",
    "        'troubleRate':troubleRate,\n",
    "        'troubleUV':troubleUV\n",
    "    }\n",
    "    return troubleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeDf(troubleDf,hosInfoRaw, devInfoRaw, data400Raw):\n",
    "    hosInfoRaw.columns = hosInfoRaw.loc[0]\n",
    "    hosInfoRaw = hosInfoRaw.set_index('HosID')\n",
    "    hosInfoRaw = hosInfoRaw.reindex(hosInfoRaw.index.dropna()).drop('HosID')\n",
    "    hosInfoRaw.index = hosInfoRaw.index.astype('int32')\n",
    "    devInfo = devInfoRaw[devInfoRaw['clock'] == devInfoRaw['clock'].loc[0]]\n",
    "    troubleDfTotal = pd.merge(troubleDf,hosInfoRaw,left_on='hos_id',right_index=True,how='left')\n",
    "    troubleDfTotal = pd.merge(troubleDfTotal,devInfo,left_on=r'GWID(网关ID)',right_on='gwid',how='left')\n",
    "    troubleDfTotal = pd.merge(troubleDfTotal,data400Raw,left_on=r'医院名称',right_on='医院名称',how='left')\n",
    "    return troubleDfTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chineseNumber(x):\n",
    "    num=['零','一','二','三','四','五','六','七','八','九']  \n",
    "    return num[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sendEmail(pathList,day,cycle):\n",
    "    user = '541546866@qq.com'\n",
    "    pwd = 'slksblakromdbfef'\n",
    "    to = ','.join(['zhiping.chen@bblink.cn'])\n",
    "    msg = MIMEMultipart()\n",
    "    title =  '%s周对比分析_%s' % (chineseNumber(cycle),str(getDate(day)))\n",
    "    message =  '附件为%s的%s周对比分析结果' %  (str(getDate(day)),chineseNumber(cycle))\n",
    "    msg['Subject'] = title\n",
    "#     msg['From'] = r'UV_MONITOR'\n",
    "    content1 = MIMEText(message, 'plain', 'utf-8')\n",
    "    msg.attach(content1)\n",
    "    for path in pathList:\n",
    "        attfile = path\n",
    "        basename = os.path.basename(attfile)\n",
    "        fp = open(attfile, 'rb')\n",
    "        att = MIMEText(fp.read(), 'base64', 'utf-8')\n",
    "        att[\"Content-Type\"] = 'application/octet-stream'\n",
    "        att.add_header('Content-Disposition', 'attachment',filename=('gbk', '', basename))\n",
    "        encoders.encode_base64(att)\n",
    "        msg.attach(att)\n",
    "    #-----------------------------------------------------------\n",
    "    s = smtplib.SMTP('smtp.qq.com')\n",
    "    s.login(user, pwd)\n",
    "    s.sendmail(user, to, msg.as_string())\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def output(day=1, cycle=1):\n",
    "    day2 = cycle*7\n",
    "    troubleInfo= analysis(day, day2)\n",
    "    pathList = []\n",
    "    for x in troubleInfo:\n",
    "        Path = r'/root/ipython/UV分析结果/%s周对比/%s_%s.xlsx' % (chineseNumber(cycle), str(getDate(day)), x)\n",
    "        troubleInfo[x].to_excel(Path)\n",
    "        pathList.append(Path)\n",
    "    sendEmail(pathList,day,cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    output()\n",
    "    output(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
